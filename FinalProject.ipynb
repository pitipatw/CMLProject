{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toward data-driven topology optimization of concrete structures\n",
    "**By Pitipat Wongsittikan, SMBT 24'**\n",
    "\n",
    "*Final project for Creative Machine Learning for Design, Spring 2023*\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "#### Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "Setup"
    ]
   },
   "outputs": [],
   "source": [
    "# for Topology optimization\n",
    "using TopOpt, LinearAlgebra, StatsFuns  \n",
    "# for Data Visualization\n",
    "using Makie, GLMakie \n",
    "# for Data Analysis\n",
    "using CSV , DataFrames\n",
    "using Clustering\n",
    "#These are for the surrogate model\n",
    "using Flux, Zygote , MLJ\n",
    "using SurrogatesFlux, Surrogates\n",
    "using Statistics\n",
    "using Random\n",
    "using Distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Makie.inline!(true) # so Makie plots are in Jupyter notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and inspect data from the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"Dataset_1.csv\", DataFrame)\n",
    "ndata = size(df)[1]\n",
    "println(\"There are $ndata data points in the dataset.\")\n",
    "# println(df[!,\"country\"])\n",
    "df_IN = df[df[!,\"country\"] .== \"IN\",:];\n",
    "df_US = df[df[!,\"country\"] .== \"US\",:];\n",
    "df_CA = df[df[!,\"country\"] .== \"CA\",:];\n",
    "df_AU = df[df[!,\"country\"] .== \"AU\",:];\n",
    "df_NZ = df[df[!,\"country\"] .== \"NZ\",:];\n",
    "df_SG = df[df[!,\"country\"] .== \"SG\",:];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check headers\n",
    "foreach(println, names(df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = Figure(resolution = (1200, 800)) \n",
    "ax1  = Axis(f1[1,1], xlabel = \"Strength [MPa]\", ylabel = \"GWP [kgCO2e/kg]\")\n",
    "ax1.title = \"Strength vs GWP\" \n",
    "# col = df[!,\"country\"];\n",
    "scatter!(ax1, df[!,\"strength [MPa]\"], df[!,\"gwp_per_kg [kgCO2e/kg]\"], color = :red, markersize = 3)\n",
    "# Legend(ax1, [\"US\", \"CA\", \"AU\", \"NZ\", \"SG\", \"IN\"])\n",
    "f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "70% for training data \n",
    "<br>15% for testing data\n",
    "<br>15% for validating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_total = collect(df[!,\"strength [MPa]\"]) ; \n",
    "y_total = collect(df[!,\"gwp_per_kg [kgCO2e/kg]\"]) ;\n",
    "data = hcat(x_total, y_total); # data is a 2 x n matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = MLJ.partition(data, 0.7, multi = true, rng = 123)# rng = Random.seed!(1234))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a neural network surrogate model using Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = Dense(1,1)\n",
    "N2 = Chain(Dense(1,10,relu), Dense(10,1))\n",
    "N3 = Chain(Dense(1,10,relu), Dense(10,10,relu), Dense(10,1))\n",
    "N4 = Chain(Dense(1,10,relu), Dense(10,10,relu), Dense(10,10,relu), Dense(10,1))\n",
    "\n",
    "models = [N1 , N2 , N3 , N4]\n",
    "\n",
    "loss1(N1, x,y) = Flux.mse(N1(x),y)\n",
    "loss2(N2,x,y) = Flux.mse(N2(x),y)\n",
    "loss3(x,y) = Flux.mse(N3(x),y)\n",
    "loss4(x,y) = Flux.mse(N4(x),y)\n",
    "\n",
    "losses = [loss1, loss2, loss3, loss4]\n",
    "\n",
    "# function my_accuracy( model , )\n",
    "opt = [Descent(0.01), Descent(0.01), Descent(0.01), Descent(0.01)]\n",
    "epoch = 500\n",
    "opt = Adam()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_log = []\n",
    "for epoch in 1:100\n",
    "  losses = Float32[]\n",
    "  for (i, data) in enumerate(train_data)\n",
    "    println(data)\n",
    "  end\n",
    "  break\n",
    "end\n",
    "    Flux.train!(loss1, Flux.params(N1), data, opt);\n",
    "    # model[1].weight\n",
    "    val = loss1(N1, data)\n",
    "\n",
    "    # val, grads = Flux.withgradient(N1) do m\n",
    "      # # Any code inside here is differentiated.\n",
    "      # # Evaluation of the model and loss must be inside!\n",
    "      # result = m(input)\n",
    "      # loss1(result, y)\n",
    "    end\n",
    "\n",
    "    # Save the loss from the forward pass. (Done outside of gradient.)\n",
    "    push!(losses, val)\n",
    "\n",
    "    # Detect loss of Inf or NaN. Print a warning, and then skip update!\n",
    "    if !isfinite(val)\n",
    "      @warn \"loss is $val on item $i\" epoch\n",
    "      continue\n",
    "    end\n",
    "    # Flux.update!(opt_state, param(N1), grads[1])\n",
    "  end\n",
    "\n",
    "  # Compute some accuracy, and save details as a NamedTuple\n",
    "  # acc = my_accuracy(model, train_set)\n",
    "  # push!(my_log, (; acc, losses))\n",
    "\n",
    "  # Stop training when some criterion is reached\n",
    "  # if  acc > 0.95\n",
    "  #   println(\"stopping after $epoch epochs\")\n",
    "  #   break\n",
    "  # end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models and plot loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Flux.mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
